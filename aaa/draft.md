It is simple to separate two points in a high-dimensional space, but when these two points are replaced by two sets of data, the problem often becomes difficult. Many times we will mix multiple sets of data together to obtain an unrepresentative result. regression model.

In this article, we hope to integrate multiple models into the EM algorithm, analyze their respective tasks for different situations, and select the optimal combination according to the actual situation.

----------------

In the data generation stage, we added a series of parameters to the data set, hoping to obtain the performance of EM under different conditions.

Offset is the distance between data in different clusters, we assume that the dimension of the data p and the number of clusters K. Then we generates a matrix uset with dimensions (p, K) where the second column contains a normalized random vector u with a magnitude of offset, and the rest of the columns are filled with zeros.



Firstly, let's assume a perfect situation. Two sets of data that we don't care about at all. The noise and variance are not too large. They are evenly distributed among each dimension, and the intervals between them are large enough.



In the initialization data stage, we use several common distributions, namely k-means, tensor-sedghi2016, and Random.

For the scale weight in E-step and M-stpe, we choose several distributions, namely tukey, huber, welsh, cauchy, and t-robust.
In regression model selection, we integrate the following methods, 'pls', 'larsen', 'least square'

### E-Step (Expectation Step):

    The likelihood of each data point belonging to a component is evaluated using the likelihood function phi.
    The weights w are updated based on the calculated likelihoods.
    The posterior likelihood is the product of the prior likelihood pr and the likelihood phi.

In the E-Step of the EM algorithm, the code calculates the likelihoods and updates the weights for each data point to determine their association with the mixture components. The goal is to assess the probability of each data point belonging to each component.

In the evaluate part, we specify the optimization and modeling process, evaluate the solution, and update the best solution based on the calculated score. Optimization terminates when certain conditions are met.

**Likelihood Calculation**

For each data point n and mixture component k. the likelihood Ï†_nk is evaluated. The likelihood measures the probability of data point n being generated by component k of the mixture model.

**Weight Update**

The weights w_nk for each data point-component pair are updated based on the calculated likelihoods. These weights represent the contribution of data point n to component k of the mixture model.



<html>
    <head>
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
        <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        <script type="module">
          import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
          mermaid.initialize({ startOnLoad: true });
        </script>
    </head>
    
    <body>
    </body>
</html>
